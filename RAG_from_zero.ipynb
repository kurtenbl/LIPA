{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb791f-1cdd-46b3-9b17-adb4a3a9ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad16c2-20ed-4e5a-a1c0-44ede7ad65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"C:/Users/linus/Universitaet/LAI/Praktikum/Textgrundlage/Archiv/Archiv2\"\n",
    "CHROMA_PATH = \"C:/Users/linus/chroma_db2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4ad92-1661-4e6d-b95d-4e33e3e48304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lade PDFs und extrahiere Dokumente\n",
    "def load_documents_from_folder(folder_path):\n",
    "    loader = PyPDFDirectoryLoader(folder_path)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8f322-5249-4dbd-a76b-98e31f114653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Splitte die Dokumente in Chunks\n",
    "def split_documents(documents, chunk_size=800, chunk_overlap=80):\n",
    "    print(\"Splitte Dokumente in kleinere Chunks...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(f\"Anzahl der Chunks: {len(chunks)}\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9fa50-4746-4160-9c36-ace902faca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_store(chunks, chroma_path, embedding_model_name=\"all-MiniLM-L12-v2\"):\n",
    "    print(\"Initialisiere Embedding-Modell...\")\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    \n",
    "    # Chroma-Client und Sammlung erstellen\n",
    "    print(\"Verbinde mit Chroma-Datenbank...\")\n",
    "    chroma_client = chromadb.PersistentClient(path=chroma_path)\n",
    "    collection = chroma_client.get_or_create_collection(name=\"pdf_documents\")\n",
    "    \n",
    "    # Embeddings erstellen\n",
    "    print(\"Erstelle Embeddings...\")\n",
    "    for chunk in tqdm(chunks, desc=\"Verarbeite Chunks\", unit=\"chunk\"):\n",
    "        text = chunk.page_content\n",
    "        embedding = model.encode(text).tolist()\n",
    "        \n",
    "        # Extrahiere den Dokumentnamen und die Seitenzahl aus den Metadaten\n",
    "        source_filename = os.path.basename(chunk.metadata.get('source', 'unbekannt'))\n",
    "        page_number = chunk.metadata.get('page', 0)\n",
    "        \n",
    "        collection.add(\n",
    "            ids=[f\"{source_filename}_page_{page_number}\"],\n",
    "            embeddings=[embedding],\n",
    "            documents=[text],\n",
    "            metadatas=[{\n",
    "                \"source\": source_filename,\n",
    "                \"page\": page_number\n",
    "            }]\n",
    "        )\n",
    "    \n",
    "    print(\"Embeddings erfolgreich in Chroma-DB gespeichert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c24ff-756e-4f3e-81e6-c26d4c48e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_folders():\n",
    "    # Fortschrittsanzeige für Ordner\n",
    "    for folder_number in tqdm(range(1, 106), desc=\"Verarbeite Ordner\", unit=\"folder\"):\n",
    "        folder_path = os.path.join(BASE_PATH, str(folder_number))\n",
    "        \n",
    "        if os.path.exists(folder_path):\n",
    "            try:\n",
    "                # Dokumente laden\n",
    "                documents = load_documents_from_folder(folder_path)\n",
    "                \n",
    "                # Dokumente in Chunks splitten\n",
    "                chunks = split_documents(documents)\n",
    "                \n",
    "                # Embeddings erstellen und speichern\n",
    "                embed_and_store(chunks, CHROMA_PATH)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Fehler bei Ordner {folder_number}: {e}\")\n",
    "        else:\n",
    "            print(f\"Ordner {folder_number} existiert nicht.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f6a48-de24-45f6-baa0-5d32b7d7439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hauptprogramm\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6cb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Chunks und Embeddings anzeigen\n",
    "folder_path = os.path.join(BASE_PATH, \"1\")  # Beispielordner\n",
    "documents = load_documents_from_folder(folder_path)\n",
    "chunks = split_documents(documents)\n",
    "\n",
    "# Beispielaufruf\n",
    "show_chunks_and_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903b339-ef3b-4116-8a37-61967dbacf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Context: \n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a detailed and precise answer based strictly on the provided context. Include all relevant information and explain the key points comprehensively. If no relevant information is found, say \"I cannot find specific information about this in the given context.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a488483-c14a-4707-ac66-98427c6bd846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "def query_rag(query_text: str, top_k: int = 5):\n",
    "    # Verwenden Sie die gleiche Embedding-Funktion wie beim Speichern\n",
    "    embedding_function = SentenceTransformer(\"all-MiniLM-L12-v2\")\n",
    "    \n",
    "    # Chroma-Client initialisieren\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "    collection = chroma_client.get_collection(name=\"pdf_documents\")\n",
    "    \n",
    "    # Embedding der Suchanfrage\n",
    "    query_embedding = embedding_function.encode(query_text).tolist()\n",
    "    \n",
    "    # Ähnlichkeitssuche\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # Kontext aus den Dokumenten extrahieren\n",
    "    context_text = \"\\n\\n---\\n\\n\".join(results['documents'][0])\n",
    "    \n",
    "    # Prompt template vorbereiten\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    \n",
    "    # LLM Aufruf\n",
    "    model = OllamaLLM(model=\"llama3.2:latest\")\n",
    "    response_text = model.invoke(prompt)\n",
    "    \n",
    "    # Quellen extrahieren\n",
    "    sources = results['ids'][0]\n",
    "    \n",
    "    # Formatierte Ausgabe\n",
    "    formatted_response = f\"Response: {response_text}\\n\\nSources: {sources}\"\n",
    "    print(formatted_response)\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0969e678-669a-4b57-bb67-2b766f682051",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_rag(\"Those are legal documents concerning 40 years of oil exploitation. Please reconstruct key events of those years.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
